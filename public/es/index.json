[{"authors":null,"categories":null,"content":"Actualmente me encuentro realizando mis estudios de doctorado en el Instituto de Radioastronomía y Astrofísica, en la Universidad Nacional Autónoma de México (UNAM). Mis principales intereses, son el estudio de las atmósferas estelares en estrellas de secuencia principal utilizando observaciones de radio y el desarrollo de soluciones para cómputo de alto rendimiento.\n  Descarga mi currículum vitae.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"es","lastmod":1615600813,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://ftapia.dev/es/author/francisco-tapia-vazquez/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/es/author/francisco-tapia-vazquez/","section":"authors","summary":"Actualmente me encuentro realizando mis estudios de doctorado en el Instituto de Radioastronomía y Astrofísica, en la Universidad Nacional Autónoma de México (UNAM). Mis principales intereses, son el estudio de las atmósferas estelares en estrellas de secuencia principal utilizando observaciones de radio y el desarrollo de soluciones para cómputo de alto rendimiento.","tags":null,"title":"Francisco Tapia Vázquez","type":"authors"},{"authors":null,"categories":null,"content":" El objetivo de este proyecto, es poder desarrollar un prototipo funcional de un cluster de computación con ordenadores de placa única u ordenadores de placa simple (SBC) de bajo coste mejor conocidos como Raspberry Pi. Detallaremos los pasos necesarios para este proyecto.   Responsables  MsC. Francisco Tapia Vázquez Dr. Victor De la Luz  Roadmap  Armado del cluster Configuración de los nodos Configuración del software Pruebas de estabilidad Optimización del cluster Lanzamiento de la versión 1.0  Cómputo de alto rendimiento ¿Qué es el cómputo de alto rendimiento? La computación de alto rendimiento (HPC en inglés) es la capacidad de procesar datos y realizar cálculos complejos a altas velocidades. Para ponerlo en perspectiva, una computadora portátil o de escritorio con un procesador de 3 GHz puede realizar alrededor de 3 mil millones de cálculos por segundo. Si bien eso es mucho más rápido de lo que cualquier ser humano puede lograr, las soluciones de HPC pueden realizar billones de cálculos por segundo.\nUno de los tipos más conocidos de soluciones HPC es la supercomputadora. Una supercomputadora contiene miles de nodos de cálculo que trabajan juntos para completar una o más tareas. A esto se le llama procesamiento paralelo. Es similar a tener miles de PC conectadas en red, combinando la potencia informática para completar las tareas más rápido.\n¿Por qué es importante la HPC? Los datos han permitido a los científicos realizar descubrimientos revolucionarios, que han permitido mejorar la calidad de vida de miles de millones de personas en todo el mundo. HPC es la base de los avances científicos, industriales y sociales.\nA medida que evolucionan tecnologías como Internet de las cosas (IoT), la inteligencia artificial (IA) y las imágenes en 3-D, el tamaño y la cantidad de datos con los que las organizaciones tienen que trabajar crece exponencialmente. Para muchos propósitos, como la transmisión de un evento deportivo en vivo, el seguimiento de una tormenta en desarrollo, la prueba de nuevos productos o el análisis de las tendencias de las existencias, la capacidad de procesar datos en tiempo real es crucial.\nPara mantenerse un paso por delante de la competencia, las organizaciones necesitan una infraestructura de TI altamente confiable y ultrarrápida para procesar, almacenar y analizar cantidades masivas de datos.\n¿Cómo funciona HPC? Existen dos métodos principales para procesar la información en HPC:\nProcesamiento en serie Es el que realizan las unidades de procesamiento central (CPU). Cada núcleo de CPU, por lo general, realiza solo una tarea a la vez. Las CPU son fundamentales para ejecutar diferentes funciones, como sistemas operativos y aplicaciones básicas (por ej., procesamiento de textos, productividad en la oficina).\n  Procesamiento en paralelo Es el que se puede realizar mediante varias CPU o unidades de procesamiento de gráficos (GPU). Las GPU, diseñadas originalmente para gráficos independientes, son capaces de realizar diferentes operaciones aritméticas por medio de una matriz de datos (como pixeles de pantalla) de forma simultánea. La capacidad para trabajar en varios planos de datos al mismo tiempo hace que las GPU sean la elección natural para el procesamiento en paralelo en tareas de aplicaciones de aprendizaje automático (AA), como el reconocimiento de objetos en videos.\n  Para construir una arquitectura informática de alto rendimiento, los servidores informáticos están conectados en red en un clúster. Los programas de software y los algoritmos se ejecutan simultáneamente en los servidores del clúster. El clúster está conectado en red al almacenamiento de datos para capturar la salida. Juntos, estos componentes funcionan a la perfección para completar un conjunto diverso de tareas.\nPara operar al máximo rendimiento, cada componente debe seguir el ritmo de los demás. Por ejemplo, el componente de almacenamiento debe poder suministrar datos hacia y desde los servidores informáticos tan rápido como se procesan. Además, los componentes de la red deben poder soportar el transporte de datos a alta velocidad entre los servidores informáticos y el almacenamiento de datos. Si un componente no puede mantenerse al día con el resto, el rendimiento de toda la infraestructura de HPC sufre.\nLa potencia de procesamiento de las computadoras se mide en unidades llamadas “FLOPS” (operaciones de punto flotante por segundo). A principios de 2019, la supercomputadora más potente que existe alcanzó los 143,5 petaFLOPS (143 × 10^15). Este tipo de supercomputadora se llama equipo de petaescala y puede realizar más de mil billones de FLOPS. Por su parte, una computadora de escritorio para juegos de alta gama es más de un millón de veces más lenta y llega apenas a los 200 gigaFLOPS (1 × 10^9). Gracias a los avances tanto en procesamiento como rendimiento, pronto seremos testigos de un nuevo salto en la era de la supercomputación: la exaescala, que será casi 1000 veces más rápida que la petaescala. Esto significa que un sistema de exaescala podrá realizar 10^18 (o mil millones por mil millones ) operaciones por segundo. 1\n¿Qué es un clúster de HPC? Un clúster de HPC consta de cientos o miles de servidores informáticos que están conectados en red. Cada servidor se llama nodo. Los nodos de cada clúster funcionan en paralelo entre sí, lo que aumenta la velocidad de procesamiento para ofrecer informática de alto rendimiento.\n  ¿Cuándo debería utilizar un clúster HPC?  Tu computadora no cuentas con suficientes recursos para ejecutar el modelo o el análisis que necesitas, ya que no cuentas con suficiente espacio de disco, memoria RAM, núcleos de procesamiento o ancho de banda en ru red doméstica. Necesitas ejectuar una tarea lo más rápido posible. Tu código necesiita ejecutar un conjunto grande de instrucciones. El software que necesitas ejecutar no es compatible con el hardware de tu computadora, tu sistema operativo, no cuentas con las licencias necesarias o tienes algún conflicto con los paquetes instalados. Tu código necesita mucho tiempo de ejecución. Necesitas paralelizarlo para bajar el tiempo de ejecución.  ¿En qué se utiliza el cómputo de alto rendimiento?  Aprendizaje automático: como subconjunto de la inteligencia artificial (IA), el aprendizaje automático (AA) se refiere a un sistema que tiene la capacidad de aprender de forma activa por sí mismo, a diferencia de recibir, de forma pasiva, instrucciones para ejecutar. Análisis de grandes conjuntos de datos: se recurre a la comparación rápida y a la correlación de grandes conjuntos de datos para complementar investigaciones y resolver problemas académicos, científicos, financieros, comerciales, gubernamentales, de salud y de seguridad cibernética. Este trabajo requiere un rendimiento masivo y capacidades de cómputo de una potencia enorme. Modelado avanzado y simulación: al no tener que realizar un montaje físico en las primeras etapas del proceso, el modelado avanzado y la simulación permiten que las empresas ahorren tiempo, materiales y costos de contratación de personal para lanzar sus productos al mercado con mayor rapidez. El modelado y la simulación en HPC se aplican en el descubrimiento y la prueba de fármacos, diseños automotrices y aeroespaciales, pronóstico de sistemas climáticos o meteorológicos, y aplicaciones energéticas.    Raspberry Pi La Raspberry Pi es una serie de ordenadores de placa reducida, ordenadores de placa única u ordenadores de placa simple (SBC) de bajo costo desarrollado en el Reino Unido por la Raspberry Pi Foundation, con el objetivo de poner en manos de las personas de todo el mundo el poder de la informática y la creación digital.​\nEn este proyecto, hemos decido crear un clúster a partir de 4 Raspberry Pi 4. Tres de ellos actúan como nodos para realizar el cálculo real y uno actúa como maestro coordinándolos y proporcionando espacio en disco al resto. Nos referiremos a este sistema maestro como un \u0026ldquo;nodo de inicio de sesión\u0026rdquo; o \u0026ldquo;nodo principal\u0026rdquo;.\nLas carecterísticas del Raspberry Pi 4 son:\n Procesador: Quad-core Cortex-A72 (ARM v8) 64-bit SoC @ 1.5 GHz. Memoria RAM: 4 GB LPDDR4-2400 SDRAM. Cache: 32 KB data + 48 KB instruction L1 cache per core. 1MB L2 cache. Códecs: H.265 (4Kp60 decode); H.264 (1080p60 decode, 1080p30 encode); OpenGL ES, 3.0 graphics Puertos: PCIe bus, onboard Ethernet port, 2 × DSI ports (only one exposed on Raspberry Pi 4B), 2 × CSI ports (only one exposed on Raspberry Pi 4B), up to 6 × I2C, up to 6 × UART (muxed with I2C), up to 6 × SPI (only five exposed on Raspberry Pi 4B), dual HDMI video output, composite video output.  Para más detalles puedes consultar la documentación oficial de Raspberry.\n  ¿Por qué construir un clúster con Raspberry Pi?  Es barato. Las placas Raspberry Pi 4 funcionan como nodos de cómputo y debido a su arquitectura, no es necesario tener una infraestructura especializada. Además, el costo de cada nodo es inferior al de uno tradicional. Es fácil de armar y configurar. Cuenta con documentación por parte de la comunidad.  Instalación En la primer parte del proyecto, vamos a revisar los accesorios que son necesarios para poder crear nuestro clúster. En la siguiente sección, vamos a mostrar los materiales que son necearios para nuestro cluster de Raspeberry Pi 4.\nMateriales necesarios  Raspberry Pi 4 (2 ó 4 GB de RAM) Memoria micro SD Adaptador de corriente Cable de red Cat 5e Switch ethernet (preferentemente Gigabit)    Materiales opcionales  Carcasa Disipadores Ventiladores Cable micro HDMI a HDMI  Estos accesorios se recomiendan para terner un mejor rendiemiento y poder elevar la frecuencia de reloj del procesador. Además, protejen a la placa del polvo y otros elementos. El cable micro HDMI es sólo si no cuentas con una computadora principal.\n  Armado del clúster El armado del cluster es sencillo. En caso de que se haya comprado disipadores, se tiene que pegar sobre la cpu, gpu y la RAM. Si cuentas con ventilador y carcasa, tendrás que atornillarlos.\n    Ese paso hay que hacerlo para cada uno de los Raspberry Pi 4 que vayamos a utilizar para el clúster.\nDespués, conectaremos los cables ethernet a cada uno de los Raspberry. Es recomendable sólo conectar un Rapsberry a la vez al switch para configurarlos individualmente. También debemos conectar los adaptadores de corriente. Al final, debemos tener algo como la siguiente imagen.\n   Hemos terminado de ensamblar nuestro clúster. Ahora, vamos a configurar a nuestro maestro y los nodos de computación.     https://www.amd.com/en/campaigns/high-performance-computing \u0026#x21a9;\u0026#xfe0e;\n   ","date":1609372800,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1615690017,"objectID":"74ed20bb2ff2a23737cd64d14b9d2efc","permalink":"https://ftapia.dev/es/raspberry/","publishdate":"2020-12-31T00:00:00Z","relpermalink":"/es/raspberry/","section":"raspberry","summary":"El objetivo de este proyecto, es poder desarrollar un prototipo funcional de un cluster de computación con ordenadores de placa única u ordenadores de placa simple (SBC) de bajo coste mejor conocidos como Raspberry Pi.","tags":null,"title":"Clúster de computacion con Raspberry Pi 4","type":"book"},{"authors":null,"categories":null,"content":"Para entender lo que significa Docker, es necesario dar un breve repaso a los contenedores.\n¿Qué es un contenedor? Un contenedor o Container, es un sandbox donde es posible ejecutar servicios y procesos en un entorno protegido. Cada contenedor se ejecuta en un Host de Contenedor, que puede ser una máquina de Windows, MacOs o Linux. Los principales beneficios de los contenedores, si se comparan con las máquinas virtuales clásicas, son los siguientes:\n La implementación es mucho más rápida. La administración es mínima. No es necesario aplicar parches y la huella es baja.  ¿Por qué contenedores? Los contenedores no son para todos y los escenarios no son muchos, en detalles:\n Sitios web Servicios Procesos Aplicaciones  Como servidor web, se puede utilizar el motor más importante, como IIS con .Net, Apache y Ngnix también; Como aplicación, podemos encontrar SQL Server para Windows o Linux y el motor de base de datos más importante.\nEn el ámbito científico, un contenedor nos proporciona una plataforma para crear escenarios avanzados que se pueden replicar fácilmente. En este sentido, un contenedor nos permite escalar códigos y adaptarlos a distintos tipos de infraestructura. Un punto importante para los desarrolladores de código, es que se pueden utilizar contenedores independientes para resolver los problemas de compatibilidad. Pensemos en el siguiente ejemplo.\n Hemos desarrollado un código que resuelve numéricamente un sistema de ecuaciones. Nuestro código lo hemos desarrollado sobre un versión específica de fortran. Inicialmente los hemos compilado y probado en nuestra computadora y funciona correctamente. Llega el momento en que queremos compartir nuestro desarrollo con la comunidad científica, pero debemos enfrentarnos al reto de que no todo el mundo cuenta con el mismo compilador o peor aún, no todo el mundo está familiarizado con el sistema operativo. Esto hace muy dificil e incluso imposible, poder colaborar con los demás miembros de la comunidad. Entonces, nos interesaría encontrar una manera de portar el código, independientemente de la arquitectura del sistema o el sistema operativo de una manera fácil.   Docker Cuando hablamos de contenedores, no podemos evitar hablar de Docker, quizás la plataforma de contenedores más conocida. Docker es una herramienta que está diseñada para beneficiar tanto a los desarrolladores como a los administradores de sistemas. Para los desarrolladores, significa que pueden centrarse en escribir código sin preocuparse por el sistema en el que finalmente se ejecutará. También les permite obtener una ventaja al usar uno de los miles de programas que ya están diseñados para ejecutarse en un contenedor Docker como parte de su aplicación. Para el personal de operaciones, Docker ofrece flexibilidad y reduce potencialmente la cantidad de sistemas necesarios debido a su tamaño reducido y menores gastos generales.\n¿Por qué no utilizar una máquina virtual? ¿Qué es una máquina virtual? Una máquina virtual es un sistema que actúa exactamente como una computadora.\nEn términos simples, hace posible ejecutar lo que parece estar en muchas computadoras separadas en hardware, es decir, una computadora. Cada máquina virtual requiere su sistema operativo subyacente y luego se virtualiza el hardware.\nDocker vs VM Las diferencias significativas son la compatibilidad con el sistema operativo, la seguridad, la portabilidad y el rendimiento.\nSoporte del sistema operativo El soporte del sistema operativo de la máquina virtual y el contenedor Docker es muy diferente. En la imagen de arriba, puede ver que cada máquina virtual tiene su sistema operativo invitado por encima del sistema operativo host, lo que hace que las máquinas virtuales sean pesadas. Mientras que, por otro lado, los contenedores Docker comparten el sistema operativo host, y es por eso que son livianos.\nCompartir el sistema operativo host entre los contenedores los hace muy ligeros y les ayuda a iniciarse en solo unos segundos. Por lo tanto, la sobrecarga para administrar el sistema de contenedores es muy baja en comparación con la de las máquinas virtuales.\nLos contenedores de la ventana acoplable son adecuados para situaciones en las que desea ejecutar varias aplicaciones en un solo kernel de sistema operativo. Pero si tiene aplicaciones o servidores que deben ejecutarse en diferentes tipos de sistemas operativos, entonces se requieren máquinas virtuales.\nSeguridad La máquina virtual no comparte el sistema operativo y existe un fuerte aislamiento en el kernel del host. Por lo tanto, son más seguros en comparación con los contenedores. Un contenedor tiene muchos riesgos de seguridad y vulnerabilidades, ya que los contenedores tienen un núcleo de host compartido.\nAdemás, dado que los recursos de la ventana acoplable se comparten y no tienen un espacio de nombres, un atacante puede explotar todos los contenedores de un clúster si obtiene acceso incluso a un contenedor. En una máquina virtual, no obtiene acceso directo a los recursos y el hipervisor está ahí para restringir el uso de recursos en una VM.\nPortabilidad Los contenedores Docker son fácilmente portables porque no tienen sistemas operativos separados. Un contenedor se puede portar a un sistema operativo diferente y puede iniciarse inmediatamente. Por otro lado, las máquinas virtuales tienen sistemas operativos separados, por lo que portar una máquina virtual es difícil en comparación con los contenedores, y también lleva mucho tiempo portar una máquina virtual debido a su tamaño.\nPara propósitos de desarrollo donde las aplicaciones deben desarrollarse y probarse en diferentes plataformas, los contenedores Docker son la opción ideal.\nDesempeño Comparar las máquinas virtuales y los contenedores Docker no sería justo porque ambos se utilizan para diferentes propósitos. Pero la arquitectura ligera de Docker es característica que consume menos recursos lo convierte en una mejor opción que una máquina virtual. Como resultado, los contenedores pueden iniciarse muy rápido en comparación con el de las máquinas virtuales, y el uso de recursos varía según la carga o el tráfico en ellos.\nA diferencia del caso de las máquinas virtuales, no es necesario asignar recursos de forma permanente a los contenedores. Escalar y duplicar los contenedores también es una tarea fácil en comparación con la de las máquinas virtuales, ya que no es necesario instalar un sistema operativo en ellas.\nResumen    Máquina virtual Contenedor Docker     Aislamiento de procesos a nivel de hardware Aislamiento de procesos a nivel de SO   Cada máquina virtual tiene un sistema operativo independiente Cada contenedor puede compartir SO   Arranca en minutos Arranca en segundos   Las máquinas virtuales son de pocos GB Los contenedores son livianos (KB / MB)   Las máquinas virtuales listas para usar son difíciles de encontrar Los contenedores Docker prediseñados están fácilmente disponibles   Las máquinas virtuales pueden moverse a un nuevo host fácilmente Los contenedores se destruyen y recrean en lugar de moverse   La creación de VM lleva relativamente más tiempo Los contenedores se pueden crear en segundos   Más uso de recursos     ","date":1609372800,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1615454713,"objectID":"b909cf83a84b4bb0fabe6d19f628eb7c","permalink":"https://ftapia.dev/es/docker/","publishdate":"2020-12-31T00:00:00Z","relpermalink":"/es/docker/","section":"docker","summary":"Para entender lo que significa Docker, es necesario dar un breve repaso a los contenedores.\n¿Qué es un contenedor? Un contenedor o Container, es un sandbox donde es posible ejecutar servicios y procesos en un entorno protegido.","tags":null,"title":"¿Qué es Docker?","type":"book"},{"authors":null,"categories":null,"content":"Clase 1   Clase 2   Presentación   ","date":1614556800,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1615454713,"objectID":"34379966878b6c5436b17bd8f707511a","permalink":"https://ftapia.dev/es/geoestadistica/introduccion/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/es/geoestadistica/introduccion/","section":"geoestadistica","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Introducción","type":"book"},{"authors":null,"categories":null,"content":"","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1615454713,"objectID":"9bf420dfacc56cf964dd372872c47534","permalink":"https://ftapia.dev/es/docker/instalacion/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/es/docker/instalacion/","section":"docker","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Instalación","type":"book"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1615454713,"objectID":"a1101cd797d6d13415e1fce065c57dc2","permalink":"https://ftapia.dev/es/raspberry/configuracion/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/es/raspberry/configuracion/","section":"raspberry","summary":"","tags":null,"title":"Configuración","type":"book"},{"authors":null,"categories":null,"content":"Clase 1    Actividad para la clase   Clase 2    Actividad para la clase   ","date":1615507200,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1616322843,"objectID":"3982f7835dedff993e17685ed0d9a9a1","permalink":"https://ftapia.dev/es/geoestadistica/analisis/","publishdate":"2021-03-12T00:00:00Z","relpermalink":"/es/geoestadistica/analisis/","section":"geoestadistica","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Análisis Exploratorio de Datos","type":"book"},{"authors":null,"categories":null,"content":" Estructura espacial. Patrones regionales. Dependencia espacial local. Modelos de covarianza espacial. Anisotropía.    ","date":1615507200,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1622530848,"objectID":"7578c7153112db442c792bcfa12fc7a3","permalink":"https://ftapia.dev/es/geoestadistica/visualizacion/","publishdate":"2021-03-12T00:00:00Z","relpermalink":"/es/geoestadistica/visualizacion/","section":"geoestadistica","summary":"Visualización","tags":null,"title":"Visualización Espacial de Datos","type":"book"},{"authors":null,"categories":null,"content":"El semivariograma.   ","date":1615507200,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1622530848,"objectID":"ca33761a831c0e9b585ee906d39b2e8d","permalink":"https://ftapia.dev/es/geoestadistica/semivariograma/","publishdate":"2021-03-12T00:00:00Z","relpermalink":"/es/geoestadistica/semivariograma/","section":"geoestadistica","summary":"Correlación","tags":null,"title":"Correlación","type":"book"},{"authors":null,"categories":null,"content":"Kriging (Parte 1)   Kriging (Parte 2)   ","date":1615507200,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1622530848,"objectID":"7d90116dea0cc87825e79daa6aaefc7c","permalink":"https://ftapia.dev/es/geoestadistica/kriging/","publishdate":"2021-03-12T00:00:00Z","relpermalink":"/es/geoestadistica/kriging/","section":"geoestadistica","summary":"Interpolación","tags":null,"title":"Interpolación","type":"book"},{"authors":null,"categories":null,"content":" Las actividades aquí presentadas, deberán entregarse la siguiente clase. El orden de presentación es aleatorio.    NO realizar la actividad, implica no obtener el puntaje correspondiente en su calificación.   Clase 1  Leer a la sección \u0026ldquo;A little history\u0026rdquo; (Páginas 6,7 y 8) del libro [Statistics in Practice] Richard Webster, Margaret A. Oliver - Geostatistics for environmental scientists que se encuentra en la bilbliografía Geoestadística. Buscar un ejemplo de aplicación en la ciencias de la tierra. Buscar un ejemplo en otras áreas de la ciencia.  Clase 2  Leer la sección \u0026ldquo;Sampling\u0026rdquo; (Páginas 6 y 7) del libro [SpringerBriefs in Agriculture] Margaret A. Oliver, Richard Webster (auth.) - Basic Steps in Geostatistics_ The Variogram and Kriging (2015, Springer International Publishing) que se encuentra en la bibliografía. Investigar que son los datos geográficos raster y los datos geográficos vectoriales. Investigar cuales son los tipos de protecciones cartográficas.   Pueden consultar el suguiente video:\n    Clase 3  ¿Correlación implica causalidad? Justifique su respuesta. Diseña un experimento para tratar de encontrar una correlación entre el dos fenómenos o situaciones sociales.  Clase 4  Buscar ¿Qué es un tree map? Investigar que es un diagrama de caja. También lo puedes encontrar en inglés como boxplot. ¿Cuál es la diferencia entre varianza y desviación estándar?  Haciendo un Análisis Geoestadístico en ArcGIS Video 1   Video 2   ","date":1615507200,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1622530848,"objectID":"81f5703511d65bd2f86ed71a4a7e9e8c","permalink":"https://ftapia.dev/es/geoestadistica/actividades/","publishdate":"2021-03-12T00:00:00Z","relpermalink":"/es/geoestadistica/actividades/","section":"geoestadistica","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Actividades","type":"book"},{"authors":null,"categories":null,"content":"Geoestadística  Estadística  Análisis Geoespacial ","date":1614556800,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1622530848,"objectID":"3803d9404b694ec739200ca79c41fffc","permalink":"https://ftapia.dev/es/geoestadistica/bibliografia/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/es/geoestadistica/bibliografia/","section":"geoestadistica","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Bibliografía","type":"book"},{"authors":null,"categories":null,"content":"Objetivos del curso  Aprender los conceptos básicos de la estadística y Geoestadística. Conocer la metodología Geoestadística y sus áreas de aplicación. Resolver un problema concreto que sea del interés del alumno.  Contenido Para el desarrollo del curso se tomará en cuenta un diagnostico del grupo durante la primer semana de clases y después de cada examen. El temario del curso se puede consultar en el PDF que se anexa debajo. Dependiendo de la evaluación inicial y de las necesidades específicas de cada uno, se propondrá y publicará un temario alternativo.\n  Temario Alternativo Basado en los resultados del examen diagnóstico, el temamario alternativo es el siguiente.\n  Fechas Importantes El Calendario oficial que nos ofrece la dirección es el siguiente. Aquí se marcan las fechas de inicio y término del curso, así como el periodo para evaluar a los alumnos. Es importante que se tenga este calendario a la mano.\n  Evaluación La evaluación se hará de la siguiente manera:\n Tareas: 30% Exposiciones: 30% Proyecto final: 40%  Durante el semestre, se tendrán 5 tareas y al menos 4 exposiciones. Las reglas para la evaluación se describen en la reglas generales.\nComunicación La forma en que nos estaremos comunicando, será mediante el Slack. Al comienzo del curso, se agregará a los alumnos a Slack en donde se darán los avisos oficiales y se responderán preguntas sobre la clase, tareas o actividades que realizemos. Adicionalmente, pueden enviarme un correo a f.tapia@irya.unam.mx, el cuál trataré de responder lo antes posible. Nuestra clase la llevaremos a cabo vía ZOOM. El link estará disponible en el canal de Slack y adicionalmente, se enviará a los alumnos vía email.\nReglas generales del curso   Es importante llegar a tiempo. Se dará un margen de 20 minutos de tolerancia. Después de este margen, se podrá ingresar al aula pero se considerará como una falta.\n  Ser respetuosos con el profesor y sus compañeros. NO se tolerará ningún tipo de violencia dentro del aula y durante el tiempo de clase.\n  Queda prohibido hacer uso de dispositivos electrónico durante la clase a menos que se requieran para desarrollar una actividad de la clase.\n  Las tareas deberán ser enviadas al correo f.tapia@irya.unam.mx el día establecido a más tardar a las 11:59 pm (hora del centro de México). En asunto deberá ir con el siguiente formato: Nombre-Tarea X.\n  Si el alumno requiere asesoría extra, se deberá agendar previamente mediante un correo electrónico en dónde se debe especificar fecha y hora. La asesoría será vía electrónica, mediante un link que será enviado al alumno.\n  Horario  Lunes: 9:00 AM a 11:00 AM Jueves: 10:00 AM a 12:00 PM  ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"es","lastmod":1615454713,"objectID":"e8c60568ee8afb13588c31d07daca2e5","permalink":"https://ftapia.dev/es/geoestadistica/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/es/geoestadistica/","section":"geoestadistica","summary":"Objetivos del curso  Aprender los conceptos básicos de la estadística y Geoestadística. Conocer la metodología Geoestadística y sus áreas de aplicación. Resolver un problema concreto que sea del interés del alumno.","tags":null,"title":"Geoestadística","type":"book"},{"authors":null,"categories":null,"content":"  Respuestas al ejercicio  Ejercicio: Dentro de una bolsa se encuentran 20 monedas, 8 de ellas son de $5, el resto son de distintas denominaciones.\n Pregunta 1  Calcula la probabilidad de sacar una moneda de $5 de la bolsa\n $$ P($5)=\\frac{8}{20}=\\frac{2}{5}=0.4 $$\nPregunta 2  Calcula la probabilidad de conseguir al menos una moneda de $5 al sacar dos monedas de la bolsa.\n Forma 1 P(al menos una moneda $5)=P($5 y otra denominación)+P(otra denominación y $5)+P($5 y $5)\n$$ P(x\\geq1)=\\frac{8}{20}.\\frac{12}{19}+\\frac{12}{20}.\\frac{8}{19}+\\frac{8}{20}.\\frac{7}{19}=\\frac{24}{95}+\\frac{24}{95}+\\frac{14}{95}=\\frac{62}{95}=0.65 $$\nForma 2 P(al menos una moneda 5) = 1 - P(no salga ninguna moneda de $5)\n$$ P(x\\geq1)=1-P(x=0)=1-\\frac{12}{20}.\\frac{11}{19}=1-\\frac{33}{95}=\\frac{62}{95}=0.65 $$\nPregunta 3  Calcula la probabilidad de conseguir al menos una moneda de $5 al sacar tres monedas de la bolsa.\n $$ P(x\\geq1)=1-P(x=0)=1-\\frac{12}{20}.\\frac{11}{19}.\\frac{10}{18}=1-\\frac{11}{57}=\\frac{46}{57}=0.8 $$\n","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1615454713,"objectID":"88e34209e020a6d1af8cf1870147965d","permalink":"https://ftapia.dev/es/geoestadistica/evaluacion-inicial/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/es/geoestadistica/evaluacion-inicial/","section":"geoestadistica","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Evaluación inicial","type":"book"},{"authors":null,"categories":null,"content":"Ahora que sabemos lo que es docker, vamos a instalarlo en nuestra computadora. Antes de instalarlo, es recomendable actualizar nuestro Windows a la versión más actual.\nOpcionalmente, podemos instalar algunos programas que nos ayudarán a tner una mejor experiencia de uso. Si ya tienes instalados estos programas, puedes dirigirte a la sección \u0026ndash;.\nInstalación de software esencial La terminal de Windows Para poder interactuar con docker, es necesario tener instalado una terminal. Podemos utilizar la terminal que por defecto tiene Windows, pero es altamente recomendable instalar la nueva versión. Para obtenerla, sólo tenemos que ir a la Microsoft Store y buscar \u0026ldquo;Windows terminal\u0026rdquo;. Y descargamos la primer aplicación. A continuación, te muestro como hacerlo desde Windows 10.\n  Git Para trabajar con proyectos open source, es bastante recomendable trabajar con un control de versiones. Git es un software diseñado por Linus Torvalds para este fin. Puede que te preguntes, ¿qué es un control de versiones? Bueno, podemos definirlo como una gestión de los diversos cambios que se realizan sobre los elementos de algún producto o configuración. Una versión, revisión o edición de un producto, es el estado en el que se encuentra el mismo en un momento dado de su desarrollo o modificación. Aunque un sistema de control de versiones puede realizarse de forma manual, es mejor disponer de herramientas que faciliten esta gestión dando lugar a los llamados sistemas de control de versiones o VCS (del inglés Version Control System). Estos sistemas facilitan la administración de las distintas versiones de cada producto desarrollado, así como las posibles especializaciones realizadas (por ejemplo, para algún cliente específico). Sii te interesa conocer más a detalle como funciona el control de versiones, puedes visitar este link.\nEn el siguiente videos te muestro cómo puedes descargar git en Windows 10.\n  Para comprobar que está activo git, puedes seguir los pasos del siguiente video.\n  Xming Para poder desplegar aplicaciones gráficas desde un contenerdor docker, es necesario contar con un servidor gráfico. Pero, ¿qué es un servidor gráfico? Un servidor gráfico o servidor de ventanas es un programa cuya tarea principal es coordinar la entrada y la salida de sus clientes hacia y desde el resto del sistema operativo, el hardware, y otros. El servidor gráfico se comunica con sus clientes con el protocolo de servidor gráfico. Un protocolo de comunicaciones que puede ser transparente a la red o simplemente con capacidad para usar la red1. Actualmente existe varios servidores gráficos, pero son dos los más populares, X11 (X.Org) y Wayland. En el siguiente video, te explico como instalar X11 en Windows 10.\n  Activar Hyper-V Para poder asignar recursos computacionales, es necesario hacer una virtualización. Windows ofrece una herramienta llamada Hyper-V. Para poder ejecutar docker correctamente, es necesario instalarla. En el siguiente video te muestro como hacerlo.\n  Instalar WSL2 Otra herramienta indipensable para poder ejecutar docker es Windows Subsystem for Linux (WSL). WSL, permiite ejecutar un amboiente GNU/Linux directamente en Windows, sin necesidad de instlar una máquina virtual tradicional como VM o un hacer un dual boot. En este video te muestro como instalar WSL2. Si quieres saber más, puedes ir a este link.\n  Instalando Docker Finalmente, procederemos a instlar docker. A continuación te explico los pasos a seguir.\n  Verificando la instalación de docker Vamos a verificar que la instalación de docker está bien. Para ello vamos a ejecutar la imagen de bienvenida a docker como se muestra en el video.\n    Artículo de Wikipedia link \u0026#x21a9;\u0026#xfe0e;\n   ","date":1609369200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1615454713,"objectID":"c0223fabc166b4fe20624a58726953ba","permalink":"https://ftapia.dev/es/docker/instalacion/windows/","publishdate":"2020-12-31T00:00:00+01:00","relpermalink":"/es/docker/instalacion/windows/","section":"docker","summary":"Ahora que sabemos lo que es docker, vamos a instalarlo en nuestra computadora. Antes de instalarlo, es recomendable actualizar nuestro Windows a la versión más actual.\nOpcionalmente, podemos instalar algunos programas que nos ayudarán a tner una mejor experiencia de uso.","tags":null,"title":"Instalando Docker en Windows","type":"book"},{"authors":null,"categories":null,"content":"Configuración inicial Para la priumer parte, necesitamos instalar el sistema operatico en los nodos y en el nodo maestro. Pra ello ingresaremos a https://www.raspberrypi.org/software/ y descargamos Raspberry Pi Imager para nuestro OS y así, poder copiar el sistema operativo en la tarjeta micro SD. Hay que seguir los pasos que se especifican en el siguiente video.\n  Después de instalar Raspian en la memoria SD, la expulsamos del equipo y la volvemos a conectar. Debemos seguir las siguientes instrucciones.\nLinux (Ubuntu)\n Abrimos una terminal ++ctrl+alt+t++ y tecleamos lo siguiente:\ncd /mnt/boot touch ssh exit  Después de eso, desmontamos la memoria SD de la computadora.\nMacOS\n Abrimos una terminal y tecleamos lo siguiente:\ncd /Volumes/boot/ touch ssh exit  Después de eso, desmontamos la memoria SD de la computadora.\nConfigurando el nodo maestro Una vez que completamos el paso anterior, colacamos la memoria SD en el el slot de la placa, conectamos el eliminador de corriente y el cable ethernet tanto en la placa como en el switch. Esperamos un par de minutos mientras se inicia el sistema operativo y abrimos la terminal de nuestro sistema operativo y tecleamos:\nssh pi@192.168.0.xx  la contraseña es raspberry. Una vez que nos permite logearnos, veremos algo como esto\nThe programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Tue Dec 22 23:34:38 2020 from 192.168.0.xx Wi-Fi is currently blocked by rfkill. Use raspi-config to set the country before use. pi@raspberrypi:~ $   Para obtener la ip de tu Raspberry, la conectamos al switch y después al router. Entramos a la página de gestión de nuestro router, generalmente la dirección del router es 192.168.0.1 la contraseña en la mayoría de los casos, se encuentra en el router. Una vez que nos logeamos, buscamos los dispotivos activos en nuestra red. Nuestro nodo maestro aparecerá como raspberry.   y vamos a seguir el siguiente tutotrial.\nCambiando el hostname y contraseña El nombre del hostname será \u0026ldquo;master\u0026rdquo;, pero podemos usar este tutorial para todos los nodos.\n  Instalando los paquetes necesarios Cuando reiniciamos la Raspberry Pi 4, vamos a actualizar los paquetes e instalar otro. Primero vamos actualizarlos\nsudo apt update  Después vamos a instalar los paquetes necesarios para la mayoría de pruebas que vamos a realizar.\nsudo apt-get install build-essential sudo apt-get install manpages-dev sudo apt-get install gfortran sudo apt-get install nfs-common sudo apt-get install nfs-kernel-server sudo apt-get install emacs sudo apt-get install openmpi-bin sudo apt-get install libopenmpi-dev sudo apt-get install openmpi-doc sudo apt-get install keychain sudo apt-get install nmap sudo apt-get install htop sudo apt-get install git  CPU (overclock) La CPU del Raspeberry Pi 4 está basada en un arquitectura ARM. Cuenta con un procesador quad-core Cortex-A72 de 64 bits. Por defecto, tiene una frecuencia de reloj de 1.5GHz para proteger al procesador de las altas temperaturas. En nuestro caso, buscamos obtener la mejor relación entre la frecuencia del reloj, voltaje y temperatura. Es necesario aclarar que no en todos los procesadores se puede elevar la frecuencia de reloj más allá de los 2.0 GHz. Esto se debe principalmente a que cuando se fabrican los procesadores, el silicio puede tener algunas imperfecciones, las cuales afectan directamente la velocidad del reloj. Tras un serie de pruebas, hemos observado que todos los Raspberry Pi 4 pueden alcanzar 2.0 GHz sin aumento drástico de temperatura (utilizando disipadores), y sólo algunos pudieron alcanzar los 2.14 GHz sin fallas por parte del sistema operativo. Por lo tanto, podemos hacer un overclock al procesador y llevarlo de manera segura hasta los 2.0 GHz.\nPara poder realizar overclock, encendemos nuestro dispositivo y editamos el archivo config.txt. Es necesario contar con privilegios de super usuario para esto. Entonces tecleamos\nsudo nano /boot/config.txt  Ahora, dentro del editor de texto tendremos que buscar la sección marcada como [pi4], bajo la cual están los ajustes específicos para este modelo de Raspberry Pi. Esto es muy bueno porque significa que si utilizáis la misma tarjeta SD con el sistema operativo en otra Raspberry Pi de generación anterior, no se aplicarán los parámetros de overclock.\nHay que ir al final del bloque de ajustes bajo [pi4] y añadir las siguientes líneas:\nover_voltage=6 arm_freq=2000  El primer ajuste, \u0026ldquo;over_voltage=6\u0026rdquo;, incrementa el voltaje de funcionamiento en aproximadamente 0.15V. Esto es necesario ya que la mayoría de Raspberry Pi 4 no arrancarán a 2.0 GHz sin este extra. Más tarde, si se quiere, se puede cambiar el valor 4 por un 2, lo que supondría un incremento de voltaje de 0.05V para reducir el calor generado, pero no hay garantías de que funcione correctamente.\n Es altamente recomendable no poner más de 6 al valor de over_voltage, ya que podría ser peligroso para la integridad del procesador.    Si la pantalla se queda en blanco o el dispositivo comienza un ciclo infinito de reinicios, tendríamos que meter la tarjeta SD en otro equipo y volver a editar el fichero fichero config.txt y esta vez edita el parámetro arm_freq, reduciendo su valor de 50 en 50 MHz. Si tienes que hacer esto, significa que tu procesador no es candidato a hacer overclock. En este caso sería mejor establecer una frecuencia de reloj de referencia para todos los nodos, por ejemplo 1800 (1.8 GHz).   El segundo ajuste, \u0026ldquo;arm_freq=2000\u0026rdquo;, establece la frecuencia de funcionamiento de los cuatro cores ARM a 2.0 GHz. Te recomendamos no elevar más este valor, ya que este es el máximo establecido por el firmware (que, por cierto, hasta hace poco era 1.75 GHz).\nUna vez que añadimos estas líneas pulsamos ++ctrl+o++ y ponemos ++enter++, después tecleamos ++ctrl+x++.\nEl siguiente paso, muy importante antes de reiniciar, es actualizar a la última versión del firmware, la que nos asegura que será compatible con la velocidad de 2.0 GHz. Para ello, hay que introducir el siguiente comando:\nsudo rpi-update  Esto cargará el actualizador de Raspberry Pi, que se encargará de manera automática de actualizar el firmware a la última versión. Cuando termine, reiniciamos el sistema con el comando\nsudo reboot  Cuando vuelva a iniciar, podemos hacer un seguimiento de la frecuancia del reloj con el comando\nwatch -n 1 vcgencmd measure_clock arm  Y listo, hemos configurado nuestro dispositivo para obtener velocidades más altas de procesamiento.\nConfigurando los demás nodos Configuración inicial Para cada uno de los nodos, cambiamos el hostname por nodox y cambiamos la frecuencia del procesador como lo vimos en la sección overclock.\n Es recomendable ir conectando y configurando un raspberry a la vez para no tener conflicto con las direcciones ip.    La contraseña debe ser la misma para cada nodo que conectemos. Esto es para facilitar su manejo.   Instalando los paquetes Para instalar los paquetes necesarios, podemos iniciar sesión en cada nodo de la siguiente manera:\nssh pi@192.168.0.xx  e instalarlos como lo vimos anteriormente.\nOtra manera de instalarlos es utilizar el paquete fabric en python. Para ello, lo instalamos en el nodo maestro de la siguiente manera\nsudo apt install fabric  Una vez instalado, creamos un archivo llamado fabfile.py y escribimos:\nfrom fabric.api import * env.hosts = [ 'pi@192.168.0.27', 'pi@192.168.0.28', 'pi@192.168.0.29', ] env.password = 'tupassword' @parallel def cmd(command): sudo(command)  En el comando env.hosts ponemos la dirección de cada uno de los nodos. Para este ejemplo, estamos utilizando un maestro y tres nodos de computación. Los nodos los hemos configurado para que sigan una secuencia de direcciones ip, pero puede ser cualquier orden de ip\u0026rsquo;s.\nLa forma en que instalamos los paquetes es la siguiente:\nfab cmd:\u0026quot;apt-get install -y update\u0026quot; fab cmd:\u0026quot;apt-get install -y build-essential\u0026quot; fab cmd:\u0026quot;apt-get install -y manpages-dev\u0026quot; fab cmd:\u0026quot;apt-get install -y gfortran\u0026quot; fab cmd:\u0026quot;apt-get install -y nfs-common\u0026quot; fab cmd:\u0026quot;apt-get install -y nfs-kernel-server\u0026quot; fab cmd:\u0026quot;apt-get install -y emacs\u0026quot; fab cmd:\u0026quot;apt-get install -y openmpi-bin\u0026quot; fab cmd:\u0026quot;apt-get install -y libopenmpi-dev\u0026quot; fab cmd:\u0026quot;apt-get install -y openmpi-doc\u0026quot; fab cmd:\u0026quot;apt-get install -y keychain\u0026quot; fab cmd:\u0026quot;apt-get install -y nmap\u0026quot; fab cmd:\u0026quot;apt-get install -y htop\u0026quot; fab cmd:\u0026quot;apt-get install -y git\u0026quot;   Hemos terminado la segunda parte de nuestro proceso. En esta parte, hemos configurado el master y los nodos con la paquetería necesaria. Ahora, nuestro objetivo será que se comuniquen entre ellos y que trabajen coordinadamente.   ","date":1609380000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1615690017,"objectID":"17ee9392c9f9b0d4c6a2023449bdd740","permalink":"https://ftapia.dev/es/raspberry/configuracion/inicial/","publishdate":"2020-12-31T03:00:00+01:00","relpermalink":"/es/raspberry/configuracion/inicial/","section":"raspberry","summary":"Configuración inicial Para la priumer parte, necesitamos instalar el sistema operatico en los nodos y en el nodo maestro. Pra ello ingresaremos a https://www.raspberrypi.org/software/ y descargamos Raspberry Pi Imager para nuestro OS y así, poder copiar el sistema operativo en la tarjeta micro SD.","tags":null,"title":"Configuración inicial","type":"book"},{"authors":null,"categories":null,"content":"   ","date":1609372800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1615454713,"objectID":"85c0420cf4da90602ea7d7bbcf7b99e8","permalink":"https://ftapia.dev/es/docker/instalacion/macos/","publishdate":"2020-12-31T01:00:00+01:00","relpermalink":"/es/docker/instalacion/macos/","section":"docker","summary":"   ","tags":null,"title":"Instalando Docker en MacOS","type":"book"},{"authors":null,"categories":null,"content":"Creando un usuario común Para lograr que todos los nodos del clúster se puedan comunicar entre ellos, es necesario que cuenten con un usuario único.\nAgregar un nuevo usuario Para agregar un nuevo usuario, debemos teclear los siguientes comandos en el nodo maestro.\ncd /home sudo useradd -m -u 1960 alpha ls -la /home  El parámetro -m especifica el directorio /home, -u es el argumento para un nueevo usuario, 1960 es el ID del usuario y alpha es el nombre del nuevo usuario. Podemos modificar el nombre por otro. Al teclear ls -la /home aparecerá el nuevo usuario creado junto con pi y root. El próximo paso, es crear un contraseña para este usuario. Teclamos entonces\nsudo passwd alpha  e introduciomos la contraseña. Para verfificar que sea ha creado correctamente el usuario y que todo está en orden, vamos a iniciar sesión con el nuevo usuario coon el siguiente comando\nsu - alpha  introducimos la contraseña y estamos dentro del usuario. Si tecleamos\nexit  regresamos al usuario pi. Ahora nos conectaremos mediante ssh al nodox y repetimos los pasos anteriores. Podemos acceder mediante\nssh nodox  y ponemos la contraseña del nodo.\n Es bueno utilizar la misma contraseña para todos los nodos.   Generar el ID key Ahora que ya configuramos el usuario en común, el nodox va a correr todos los programas MPI. Vamos a generar un llave especial que permitirá conectarnos mediante ssh sin contraseña de un nodo a otro, o del nodo maestro a un nodo las veces que lo necesitemos. Para hacer esto nos situamos en el nodo maestro y después, nos conectamos al usuario alpha mediante\nsu - alpha  y una vez adentro, teclamos los siguiente\nssh-keygen -t rsa  en donde -t es el argumento y rsa es el tipo de encriptación. Para generar la clave necesitamos ingresar\n El nombre del archivo donde vamos a guardar la clave Ingresar la passphrase (escogeremos la frase de nuestra elección) Reingresamos la passphrase  y tendremos que ver una imagen como la siguiente\n+--[ RSA 2048]----+ | o=. | | o o++E | | + . Ooo. | | + O B.. | | = *S. | | o | | | | | | | +-----------------+  Copiar la clave a los demás nodos Ya que generamos la clave, la vamos a transferir al nodox con el siguiente comando\nssh-copy-id alpha@nodox; alpha  y teclamos el passphrase. Para verificar que se tranfirió bien la clave, nos conectaremos al nodo de la siguiente manera\nssh nodox  e introducimos el passphrase nuevamente e ingresaremos al nodox. Ahora regresamos al nodo maestro mediante exit y listamos los archivos en el usuario alpha utilizando ls -la. Indentificamos la carpeta .ssh y vemos lo que está adentro con ls -la .ssh. Ahí vamos a ver estos tres archivos\n id_rsa id_rsa.pub known_hosts  Si nos intentamos conectar nuevamente al nodox, nos va a solicitar la passphrase. Esto no es lo que estamos buscando, por lo que aún debemos realizar algunos cambios en nuestro nodo maestro. Regresamos al nodo maestro mediante exit o cerrando la ventana de la terminal y conectandonos al modo maestro. Nos percatamos que nos encontramos en el usurio alpha, si no es así ingresamos mediante su - alpha. Vamos a editar el archivo llamado .bashrc dentro de nuestro directorio de inicio. Abrimos el archivo con nuestro editor favorito, puede ser emacs, vim, nano o pico. Nano viene instalado por defecto, entonces lo utilizaremos en esta guía. Entonces teclamos\nnano .bash  nos vamos hasta el final del archivo y agregamos el siguiente texto\n#Logic for keychain /usr/bin/keychain $HOME/.ssh/id_rsa source $HOME/.keychain/$HOSTNAME-sh  y tecleamos ctrl + o para guardar y ctrl + x para salir. Entonces recompilamos el archivo .bashrc mediante\nsource .bashrc  volvemos a ingresar el passphrase. Ahora nos volvemos a conectar al nodox con\nssh nodox  y ¡listo!, nos hemos conectado al nodox. Vamos a repetir este proceso para cada nodo del clúster.\nCreando una carpeta compartida Para que los datos puedan ser accesibles para todos los nodos, es necesario crear un repositorio. Vamos a montarlo en el nodo maestro de la siguiente manera. Primero, vamos a crear la carpeta que va a ser compartida.\nsudo mkdir /beta  en este caso la montanmos en el directorio raíz / y la llamaremos beta. Le cederemos la propiedad al usuario alpha, ya que es el usuario común. Entonces tecleamos\nsudo chown alpha:alpha /beta/  el directorio /beta ahora puede ser accedido por el usuario y grupo alpha. El siguiente paso es modificar el servicio rpcbind para poder exportar el directorio a los demás nodos. tecleamos\nsudo rpcbind start sudo update-rc.d rpcbind enable  la segunda línea es para especificar que el servicio se ejecute cada vez que se inicia el sistema. Tenemos ahora que especificar que directorio en el nodo maestro va a estar disponible para ser montado por los demás nodos. Para ellos vamos a modificar el archivo exports abriendolo con sudo emacs /etc/exports ya añadiendo al final del archivo la siguiente línea\n#beta /beta 192.168.0.0/24(rw,sync)  Salvamos con ctrl+x+ctrl+s y salimos con ctrl+x+ctrl+c.\nEn este caso /betaes la carpeta en el nodo maestro que vamos a exportar. 192.168.0.0/24 significa que las direcciones IP pueden en un rango entre 192.168.0.0 y 192.168.0.255 pueden montar el directorio /beta. rw significa que se puede leer y escribir en ella. Para que tenga efecto el cambio que realizamos, necesitamos reiniciar el servicio nfs-kernel-servercon sudo service nfs-kernel-server restart. Se puede automatizar este proceso cada vez que inicie el sistema. Para ello necesitamos mofdificar el archivo sudo emacs /etc/rc.local y poner en la penúltima línea, antes de exit 0 lo sigueinte\nsudo service nfs-kernel-server restart  guardamos y cerramos el archivo. Vamos a hacer un test. Nos conectamos al nodox con ssh nodox y una vez dentro, teclamos los siguiente\nsudo mkdir /beta sudo chown alpha:alpha /beta sudo mount master:/beta /beta  hemos creado un directorio llamado \\beta que ahora le pertenece al usuario y al grupo alpha. Después, le indicamos que monte el directorio /beta del master en /beta. Para probar que todo ha sido ejecutado de manera correcta, vamos a cambiar al usuario alpha con su - alpha. Para ver los directorio que se encuentran en la carpeta raíz hacemos la -la / y debe aparecer /beta, nos cambiamos a ese directorio con cd /beta y creamos un archivo echo \u0026quot;Hola mundo\u0026quot; -\u0026gt; hola.txt. Regresamos al usuario picon exit y ahora nos conectamos de vuelta al nodo maestro ssh master. Una vez en el nodo maestro podemos ver si el archivo se ha guardado en el directorio compartido con ls -la /beta. Ahí debe aparecer el archivo hola.txty si hacemos cat /beta/hola.txt nos debe aparecer la frase Hola mundo.\n Hemos configuirado nuestro clúster de manera correcta. En la siguiente sección, vamos a hacer algunas pruebas.    --- ","date":1609380000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1615690017,"objectID":"c1946f2058fc4736aab908fce1cbab16","permalink":"https://ftapia.dev/es/raspberry/configuracion/nodos/","publishdate":"2020-12-31T03:00:00+01:00","relpermalink":"/es/raspberry/configuracion/nodos/","section":"raspberry","summary":"Creando un usuario común Para lograr que todos los nodos del clúster se puedan comunicar entre ellos, es necesario que cuenten con un usuario único.\nAgregar un nuevo usuario Para agregar un nuevo usuario, debemos teclear los siguientes comandos en el nodo maestro.","tags":null,"title":"Configuranción de los nodos","type":"book"},{"authors":null,"categories":null,"content":"En el caso de linux, las cosas son más simples para trabajar con docker. En primer lugar, la mayoría de las distribuciones modernas (Ubuntu, CentOS, Fedora, etc.) incluyen por defecto un servidor gráfico, ya sea X.org o Wayland, por lo que para trabajar con docker y con proyectos open source, sólo es necesario verificar que contemos con git para el control de versiones e instalar docker.\nEn el siguiente video, te muestro como verificar e instalar git y docker.\n  ","date":1609380000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1615454713,"objectID":"5b6a0b0039f6e99fd9a57a5d18e13ba2","permalink":"https://ftapia.dev/es/docker/instalacion/linux/","publishdate":"2020-12-31T03:00:00+01:00","relpermalink":"/es/docker/instalacion/linux/","section":"docker","summary":"En el caso de linux, las cosas son más simples para trabajar con docker. En primer lugar, la mayoría de las distribuciones modernas (Ubuntu, CentOS, Fedora, etc.) incluyen por defecto un servidor gráfico, ya sea X.","tags":null,"title":"Instalando Docker en Linux","type":"book"},{"authors":null,"categories":null,"content":"Probando nuestro clúster Aplicaciones en paralelo Llamada de procesos Para esta parte, vamos a ejecutar una serie de códigos en parelelo para comprobar la comunicación entre los nodos. Para ello vamos a clonar el repositorio de pruebas siguiendo estos pasos:\nsu - alpha cd /beta/ git clone https://gitlab.com/fratava/cluster-pi.git cd cluster-pi  Para la primera prueba, vamos a comprobar que hay intercomunicación entre los nodos del clúster. Para evitar estar listando los núcleos que vamos a utilizar, crearemos una archivo en dónde le vamos a indicar a MPI los nodos con los cuales va a estalecer la comunicación dinámicamente. Es muy recomendable contar con este archivo, ya que de otra manera hay que indicarle explícitamente los núcleos de los nodos que vamos a utilizar.\nCreamos el archivo llamado #!bash machinefile de la siguiente manera\nemacs machinefile  y escribimos\nnodo1 nodo2 nodo3 master  pulsamos ctrl+s y ctrl+x.\n Si añadimos más nodos de cómputo a nuestro clúster o queremos hacer una segmentación, debemos modificar nuestro machinefile para agregar o remover nodos.   Compilamos el código\nmpicc call-procs.c -o call-procs  y los ejecutamos\nCon machinefile\nmpiexec -machinefile machinefile -n 16 ./call-procs  Sin machinefile\nmpiexec -H master,master,master,master,nodo1,nodo1,nodo1,nodo1,nodo2,nodo2,nodo2,nodo2,nodo3,nodo3,nodo3,nodo3 ./call-procs  Si todo marcha bien debemos tener una salida como esta\nLlamada al proceso 3 de 16 en master Llamada al proceso 2 de 16 en master Llamada al proceso 0 de 16 en master Llamada al proceso 1 de 16 en master Llamada al proceso 15 de 16 en nodo3 Llamada al proceso 12 de 16 en nodo3 Llamada al proceso 5 de 16 en nodo1 Llamada al proceso 6 de 16 en nodo1 Llamada al proceso 14 de 16 en nodo3 Llamada al proceso 8 de 16 en nodo2 Llamada al proceso 13 de 16 en nodo3 Llamada al proceso 7 de 16 en nodo1 Llamada al proceso 9 de 16 en nodo2 Llamada al proceso 4 de 16 en nodo1 Llamada al proceso 10 de 16 en nodo2 Llamada al proceso 11 de 16 en nodo2  Recordemos que las llamadas son aleatorias.\n En algunas ocasiones, podrías no tener esta salida. En este caso deberás revisar que tu cable de red está bien conectado, tu raspberry está prendida o tu volumen está montado. Para verificar esto último podemos teclear\ncd /beta ls  Si el folder está vacío debemos teclear\nsudo mount master:/beta /beta  y volvemos a ejecutar el código.\n  Calculando Pi en paralelo Ahora calcularemos Pi de forma paralela. Para esto, haremos una integración numérica. La idea detrás de este algoritmo la podemos encontrar en esta página.\nProcedemos entonces a ejecutar el código. Primero lo compilamos\nmpicc pi_mpi.c -o pi_mpi  y lo ejecutamos\nCon machinefile\nmpiexec -machinefile machinefile -n 16 ./pi_mpi  Sin machinefile\nmpiexec -H master,master,master,master,nodo1,nodo1,nodo1,nodo1,nodo2,nodo2,nodo2,nodo2,nodo3,nodo3,nodo3,nodo3 ./pi_mpi  En este caso no solicitará el número de rectángulos\n####################################################### Master node name: master Enter the number of intervals:  El valor queda al criterio del usuario. A continuación, te mostramos a modo de ilustración, los resultados que se obtienen para 300000 rectángulos cuando se calcula Pi con diferentes números de procesadores, los cuales los designaremos con \u0026ldquo;n=??\u0026rdquo; y #!bash time antes de la ejecución para medir el tiempo.\nn=1\nalpha@master:/beta/cluster-pi $ time mpiexec -machinefile machinefile -n 1 ./pi_mpi ####################################################### Master node name: master Enter the number of intervals: 300000 *** Number of processes: 1 Pi Calculado = 3.141592653590713268840772798285 Pi = 3.141592653589793115997963468544 Error relativo = 0.000000000000920152842809329741 real\t8m54.547s user\t8m47.000s sys\t0m0.160s  n=2\nalpha@master:/beta/cluster-pi $ time mpiexec -machinefile machinefile -n 2 ./pi_mpi ####################################################### Master node name: master Enter the number of intervals: 300000 *** Number of processes: 2 Pi Calculado = 3.141592653590711492483933398034 Pi = 3.141592653589793115997963468544 Error relativo = 0.000000000000918376485969929490 real\t4m36.129s user\t8m58.883s sys\t0m0.211s  n=4\nalpha@master:/beta/cluster-pi $ time mpiexec -machinefile machinefile -n 4 ./pi_mpi ####################################################### Master node name: nodo3 Enter the number of intervals: 300000 *** Number of processes: 4 Pi Calculado = 3.141592653590712824751562948222 Pi = 3.141592653589793115997963468544 Error relativo = 0.000000000000919708753599479678 real\t2m19.781s user\t9m10.213s sys\t0m0.228s  n=8\nalpha@master:/beta/cluster-pi $ time mpiexec -machinefile machinefile -n 8 ./pi_mpi ####################################################### Master node name: master Enter the number of intervals: 300000 *** Number of processes: 8 Pi Calculado = 3.141592653590715045197612198535 Pi = 3.141592653589793115997963468544 Error relativo = 0.000000000000921929199648729991 real\t1m26.563s user\t4m44.188s sys\t0m12.459s  n=16\nalpha@master:/beta/cluster-pi $ time mpiexec -machinefile machinefile -n 16 ./pi_mpi ####################################################### Master node name: master Enter the number of intervals: 300000 *** Number of processes: 16 Pi Calculado = 3.141592653590720818357340249349 Pi = 3.141592653589793115997963468544 Error relativo = 0.000000000000927702359376780805 real\t0m59.547s user\t2m41.094s sys\t0m30.697s  Como podemos darnos cuenta, el tiempo de ejecución, baja a medida que aumentamos el número de procesadores.\n Ahora que tenemos nuestro clúster funcionando, desarrollaremos códigos parelelos. Pero como lo hemos mencionado en la introducción, podemos utilizar nuestro clúster para diversas tareas.   ","date":1609372800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1615690017,"objectID":"a22e2af24ef4a980d775acb569de4697","permalink":"https://ftapia.dev/es/raspberry/test/","publishdate":"2020-12-31T00:00:00Z","relpermalink":"/es/raspberry/test/","section":"raspberry","summary":"Probando nuestro clúster Aplicaciones en paralelo Llamada de procesos Para esta parte, vamos a ejecutar una serie de códigos en parelelo para comprobar la comunicación entre los nodos. Para ello vamos a clonar el repositorio de pruebas siguiendo estos pasos:","tags":null,"title":"Test","type":"book"},{"authors":["White, Jacob Aaron","Francisco Tapia Vázquez","Hughes, A. G","Moór, A","Matthews, B","Wilner, D","Aufdenberg, J","Fehér, O","Hughes, A. M","De la Luz, V","McNaughton, A","Zapata, L. A."],"categories":null,"content":"","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1620097225,"objectID":"4bfc8fb826f936aeb445626f75593598","permalink":"https://ftapia.dev/es/publication/white-2021/","publishdate":"2021-05-03T00:00:00Z","relpermalink":"/es/publication/white-2021/","section":"publication","summary":"Presentamos el primer espectro en radio de una estrella de tipo espectral A.","tags":["Atmósferas Estelares","Cromosferas","Estrellas de secuencia principal","Radioastronomía"],"title":"The First Radio Spectrum of a Rapidly Rotating A-type Star","type":"publication"},{"authors":["Francisco Tapia Vázquez","White, J","De la Luz, V","Zapata, L"],"categories":null,"content":"The dominant emission mechanisms at millimeter/submillimeter remain largely unknown for most spectral types other than Solar analogues. This is due in part to the lack of data to inform stellar atmosphere models. In this work, we present a new methodology to fit the observed and synthetic spectrum of main-sequence stars through semiempirical models1. We use the Levenberg-Marquardt algorithm as a Nonlinear method, PakalMPI2 as the semiempirical model and the observations that are part of an ongoing observational campaign entitled Measuring the Emission of Stellar Atmospheres at Submillimeter/ Millimeter wavelengths3. Our results show that we can use semiempirical models as an input model to reproduce and constrain the observed spectrum of main-sequence stars4. In addition to a better understanding of stellar processes, these models are also essential for determining the stellar contribution to unresolved circumstellar disks at submillimeter/millimeter wavelengths5.\nToday I\u0026#39;m going to present a project that @Jacob_White26 and I have been working on at the #AAS237 meeting. The talk is titled \u0026quot;MESAS Meets KINICH-PAKAL: Measure and Modeling Main Sequence Stellar Atmospheres\u0026quot; 1/n\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  This work has an observational and theoretical basis. MESAS is an ongoing observational campaign that seeks to obtain a broad spectral sub-mm/cm coverage of a range of spectral types to build a more complete catalog of stellar emission. 2/n #AAS237\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  Nowadays, the spectrum of stars in this range remains poorly constrained due to a lack of data for most spectral types. This situation is due in part to the technical limitations of these wavelengths. 3/n #AAS237\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  The development of more sensitive detectors has made it possible to observe for the first time, stars of main-sequence at sub-mm / mm wavelengths. The Stars with no known circumstellar material to provide valuable information about the physical conditions of the atmosphere. 4/n\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  This information is useful to characterize the emission and use it as a template for several studies in many areas such as: stellar atmospheres, debris disks, space weather, stellar evolution, and long term stellar variability studies. 5/n #AAS237\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  As an example, we have the case of Sirius A an A1Vm star. Due to its proximity (2.64 pc), it was a good starting point to start studying the emission of A stars. The results can be found in White et al. (2019) https://t.co/WPWzt6y31t . 6/n #AAS237 pic.twitter.com/8PqaUaCf5s\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  For the theoretical part, we have Kinich-Pakal (KP). KP is a new methodology developed by @victor_delaluz and me, to fit the observed and synthetic spectrum of solar-like stars from the centimeter to infrared wavelengths through semiempirical models. 7/n #AAS237\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  KP uses the Levenberg-Marquardt algorithm to minimize the differences between synthetic and observed spectrum by running PakalMPI (De la Luz et al., 2010) https://t.co/dIKB1QU21j to hydrostatically equilibrate the atmosphere and to compute their synthetic spectrum. 8/n #AAS237\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  KP is capable of finding the physical conditions such as pressure, density, and temperature in function of the altitude. As an example, we have the model of Alpha Centauri A (Tapia-Vázquez \u0026amp; De la Luz, 2020) https://t.co/swRBqlKAFG . 9/n #AAS237\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  Alpha Centauri A and B were the first stellar system resolved in the submillimeter wavelength by ALMA (Liseau et al. 2015). Thanks to these observations and the sun-like properties of alpha Centauri, we could calibrate the model. 10/n #AAS237\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  As a result, we obtain a semi-empirical model that allows us to reproduce the observed spectrum more closely. This model shows similarities between Alpha Centauri A and our Sun, such as a low temperature, a flattening of the temperature in the high chromosphere. 11/n #AAS237 pic.twitter.com/swXi2l6434\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  But, in a broad stellar context, both MESAS and KINICH-PAKAL works as a compliment. MESAS provides an observational framework that constrains the stellar emission, and KP uses this information to model the atmosphere. 12/n #AAS237\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  Using both, we have been able to characterize the emission in stars of spectral type F from the radio to the infrared wavelengths such as Gamma Vir A/B (F0V) and Gamma Lep (F6V) (White et al. 2020) https://t.co/oB5ELqvXzQ . 13/n #AAS237 pic.twitter.com/vBFPhDA0pp\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  As future work, we are going to expand the use of this framework with the help of more observations that will come primarily from the #VLA, @almaobs, #Noema, and the @gtmlmt_oficial. 14/n #AAS237\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  The complete keynote can be found at https://t.co/R8sfncEuua :) Thanks to @Jacob_White26, @victor_delaluz, and Luis Zapata for the comments and the help! 15/n #AAS237\n\u0026mdash; Francisco Tapia 📡 (@ftapia_va) January 11, 2021  References   Tapia-Vázquez, F., \u0026amp; De la Luz, V. 2020, ApJS, 246, 5 Doi \u0026#x21a9;\u0026#xfe0e;\n De la Luz, V., Lara, A., Mendoza-Torres, J. E., et al. 2010, ApJS, 188, 437 Doi \u0026#x21a9;\u0026#xfe0e;\n White, J.A., Aufdenberg, J., Boley, A.C., 2018, ApJ,859(2), p.102. Doi \u0026#x21a9;\u0026#xfe0e;\n White, J. A., Tapia-Vázquez, F., Hughes, A. G., et al. 2020, ApJ, 894, 76 Doi \u0026#x21a9;\u0026#xfe0e;\n White, J. A., Aufdenberg, J., Boley, A. C., et al. 2019, ApJ, 875, 55 Doi \u0026#x21a9;\u0026#xfe0e;\n   ","date":1609977600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1616142656,"objectID":"996c4ccadaaa9e930e7c0cc5f302a4d6","permalink":"https://ftapia.dev/es/publication/aas237/","publishdate":"2021-01-07T00:00:00Z","relpermalink":"/es/publication/aas237/","section":"publication","summary":"Presentation No.116.01 in the session “Stellar Atmospheres and Winds”.","tags":["AAS237"],"title":"MESAS Meets KINICH-PAKAL: Measure and Modeling Main Sequence Stellar Atmospheres","type":"publication"},{"authors":["White, Jacob Aaron","Francisco Tapia Vázquez","Hughes, A. G","Moór, A","Matthews, B","Wilner, D","Aufdenberg, J","Hughes, A. M","De la Luz, V","Boley, A. C"],"categories":null,"content":"","date":1588809600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1615454713,"objectID":"eab1db723e08cd2fdd69bce2bfe1b3e7","permalink":"https://ftapia.dev/es/publication/white-2020/","publishdate":"2020-05-07T00:00:00Z","relpermalink":"/es/publication/white-2020/","section":"publication","summary":"We present Atacama Large Millimeter/submillimeter Array observations of the three nearby, main-sequence, debris-poor, F-type stars γ Lep, γ Vir A, and γ Vir B at 0.87 and 1.29 mm.","tags":["Atmósferas Estelares","Cromosferas","Estrellas de Secuencia Principal","Radioastronomía"],"title":"The MESAS Project: ALMA Observations of the F-type Stars γ Lep, γ Vir A, and γ Vir B","type":"publication"},{"authors":["Francisco Tapia Vázquez","De la Luz, V"],"categories":null,"content":"","date":1578355200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1615454713,"objectID":"f66f2233dfdeb60243daaf77d28beb9f","permalink":"https://ftapia.dev/es/publication/ftapia-2020/","publishdate":"2020-01-07T00:00:00Z","relpermalink":"/es/publication/ftapia-2020/","section":"publication","summary":"In this work, we present a new methodology to fit the observed and synthetic spectrum of main-sequence stars through semiempirical models.","tags":["Atmósferas Estelares","Cromosferas","Estrellas de Secuencia Principal","Radioastronomía"],"title":"Nonlinear Convergence of Solar-like Stars Chromospheres Using Millimeter, Submillimeter, and Infrared Observations","type":"publication"},{"authors":["White, Jacob Aaron","Aufdenberg, J","Boley, A. C","Devlin, M","Dicker, S","Hauschildt, P","Hughes, A. G","Hughes, A. M","Mason, B","Matthews, B","Moór, A","Mroczkowski, T","Romero, C","Sievers, J","Stanchfield, S","Francisco Tapia Vázquez","Wilner, D"],"categories":null,"content":"","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1615454713,"objectID":"6e0047c12311586bd2dd9916fbb80aca","permalink":"https://ftapia.dev/es/publication/white-2019/","publishdate":"2019-04-07T00:00:00Z","relpermalink":"/es/publication/white-2019/","section":"publication","summary":"Here we present Atacama Large Millimeter/submillimeter Array, Green Bank Telescope, and Very Large Array observations of Sirius A, the closest main-sequence A-type star, that span from 1.4 to 9.0 mm.","tags":["Atmósferas Estelares","Cromosferas","Estrellas de Secuencia Principal","Radioastronomía"],"title":"The MESAS Project: Long-wavelength Follow-up Observations of Sirius A","type":"publication"},{"authors":[],"categories":[],"content":" Modeling Altair’s Atmosphere Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1620097225,"objectID":"29687159188cf561b188bf0b4715c58f","permalink":"https://ftapia.dev/es/slides/aas238/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/es/slides/aas238/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Liseau, R","De la Luz, V","O'Gorman, E","Bertone, E","Chavez, M","Francisco Tapia Vázquez"],"categories":null,"content":"","date":1475798400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1615454713,"objectID":"8257dee915f5d3c2693d4e393bf1b6e8","permalink":"https://ftapia.dev/es/publication/liseau-2016/","publishdate":"2016-10-07T00:00:00Z","relpermalink":"/es/publication/liseau-2016/","section":"publication","summary":"The precise mechanisms that provide the nonradiative energy for heating the chromosphere and corona of the Sun and other stars are at the focus of intense contemporary research.","tags":["Atmósferas Estelares","Cromosferas","Estrellas de Secuencia Principal","Radioastronomía"],"title":"ALMA's view of the nearest neighbors to the Sun. The submm/mm SEDs of the α Centauri binary and a new source","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1615454713,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://ftapia.dev/es/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/es/project/external-project/","section":"project","summary":"Grupo Interdisciplinario de Cómputo Científico.","tags":["HPC","UNAM","Cómputo"],"title":"GICC","type":"project"},{"authors":null,"categories":null,"content":"La atmósfera de las estrellas de tipo solar está compuesta por la fotosfera, la cromosfera, la zona de transición y la corona. La cromosfera es la capa donde la temperatura va de 4000 K a 8000 K y se estudia en longitudes de onda ultravioleta, visible, infrarroja, milimétrica y (sub) milimétrica (Wedemeyer et al. 2016) 1. Los primeros modelos cromosféricos se obtuvieron gracias a las observaciones ultravioleta (Vernazza et al. 1981; Avrett \u0026amp; Loeser 2008) 2 3. Sin embargo, observaciones recientes realizadas con el Telescopio Solar Submilimétrico (SST) y el Atacama Large Millimeter / Submillimeter Array (ALMA) han demostrado que la cromosfera tiene temperaturas más bajas de lo esperado por los modelos ultravioleta (Linsky 2017). 4\nHemos desarrollado el código KINICH-PAKAL (Tapia-Vázquez, \u0026amp; De la Luz 2020) 5 que utiliza el algoritmo Levenberg-Marquard como método de ajuste no lineal, PAKAL-MPI como modelo cromosférico de la atmósfera solar y observaciones en longitudes de onda que van desde el infrarrojo al milímetro para generar un modelo más preciso de las cromosferas de las estrellas de tipo solar. KINICH-PAKAL nos ha permitido estudiar en detalle cómo cambian las condiciones físicas de la atmósfera en función de su temperatura efectiva. El desarrollo de estos modelos es necesario para estudios de discos de escombros (White et al. 2018) 6, estudiar las condiciones bajo las cuales se forman las erupciones (MacGregor et al. 2018) 7 y los posibles mecanismos físicos de variaciones de flujo en el estrellas (Liseau 2019) 8.\nReferencias   Wedemeyer, S., Bastian, T., Brajša, R., et al. 2016, SSRv, 200, 1. \u0026#x21a9;\u0026#xfe0e;\n Vernazza, J. E., Avrett, E. H., \u0026amp; Loeser, R. 1981, ApJS,45, 635. \u0026#x21a9;\u0026#xfe0e;\n Avrett, E. H., \u0026amp; Loeser, R. 2008, ApJS, 175, 229. \u0026#x21a9;\u0026#xfe0e;\n Linsky, J. L. 2017, ARA\u0026amp;A, 55, 159. \u0026#x21a9;\u0026#xfe0e;\n Tapia-Vázquez, F., \u0026amp; De la Luz, V. 2020, ApJS, 246, 5. \u0026#x21a9;\u0026#xfe0e;\n White, J.A., Aufdenberg, J., Boley, A.C., 2018, ApJ,859(2), p.102. \u0026#x21a9;\u0026#xfe0e;\n MacGregor, M. A., Weinberger, A. J., Wilner, D. J., Kowalski, A. F., \u0026amp; Cranmer, S. R. 2018, ApJ, 855, L2. \u0026#x21a9;\u0026#xfe0e;\n Liseau, R. 2019, arXiv:1904.03043. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1615454713,"objectID":"7fac3a44e9eef6ede66667602e35eb05","permalink":"https://ftapia.dev/es/project/kinich-pakal/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/es/project/kinich-pakal/","section":"project","summary":"Atmósferas estelares en estrellas de tipo solar a longitudes de onda milimétricas y submilimétricas.","tags":["Estelar","Radioastronomía"],"title":"Kinich Pakal","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1616322843,"objectID":"efc1160a5ab2a0bded2ff78d4573c078","permalink":"https://ftapia.dev/es/project/mesas/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/es/project/mesas/","section":"project","summary":"Measuring the Emission of Stellar Atmospheres at Submillimeter/millimeter wavelengths.","tags":["Radioastronomía","Submilimétrico","Milimétrico","Atmósferas Estelares"],"title":"MESAS","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1615454713,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://ftapia.dev/es/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/es/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]